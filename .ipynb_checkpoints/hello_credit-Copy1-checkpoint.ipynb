{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5bebd14-5939-4228-9449-e42827616343",
   "metadata": {},
   "source": [
    "# **Predictive Default Risk Assessor V.01**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa758ff1-aff3-4718-a6b6-2bf4aa81d71f",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* Base model \n",
    "* Comparison\n",
    "* Specialised\n",
    "* For small entities - Examples?\n",
    "* Backtest - All sectors \n",
    "* Understanding the model across all sectors/industries\n",
    "* Any markets - consumer goods, industries\n",
    "* UI last step after backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cebbf57d-65db-4819-98a2-b2ab40d50e03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import namedtuple\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, accuracy_score, mean_absolute_percentage_error\n",
    "from dataclasses import dataclass\n",
    "from quantstats import * \n",
    "from hellocredit import *\n",
    "from hellocredit.utils import get_rating_meta\n",
    "from hellocredit import calculate_credit_rating, get_nested_dict\n",
    "extend_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e18cec6-57a3-4afa-8caf-f3d2cb83b203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a52cdfd7-5b47-44fd-b3ef-ebfc7ce45258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = pd.read_excel(\"dataset/target.xlsx\", index_col=0)['numeric_rating']\n",
    "jse_all_share = [stock for stock in targets.index if \"SJ\" in stock]\n",
    "features = pd.read_excel(\"dataset/jalsh_dataset.xlsx\", sheet_name=\"data\", index_col=0, parse_dates=True, header=[0, 1])\n",
    "features = features[jse_all_share]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "80cb5943-54f7-4a8e-95d7-07f8bf08f483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = features.mean().unstack()\n",
    "y = targets.loc[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda3d3cf-21f8-4802-b963-dcaad39dbbdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d243e0-162b-451b-a997-481ebbcf173a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dc2e718b-a05d-465c-81f0-5e0793a8d2be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b2ef71dd-3e10-435e-b4d0-e8a382c5efeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "75005cde-e6c5-4d1d-b13f-4fa445f3ab60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.18569958847736556"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HistGradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "513b3f19-42a9-4dac-ac03-0e5940e1ec53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24.000000\n",
       "mean     13.883184\n",
       "std      16.690738\n",
       "min      -2.374057\n",
       "25%       5.409520\n",
       "50%       8.592150\n",
       "75%      14.268756\n",
       "max      76.656669\n",
       "Name: EBITDA_TO_TOT_INT_EXP, dtype: float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c99dd11a-35bc-4421-a7a3-06f2b0c5254d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = pd.read_excel(\"dataset/jalsh_dataset.xlsx\", sheet_name=\"data\", index_col=0, parse_dates=True, header=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bdc351b9-5ad3-41dd-8a5c-e0ec80662acc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = features.mean().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3bbccdf8-9a4c-4ada-8c97-49aa7a70650e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    121.000000\n",
       "mean       7.166755\n",
       "std        5.727359\n",
       "min       -2.835850\n",
       "25%        2.456150\n",
       "50%        6.490792\n",
       "75%        9.984608\n",
       "max       31.639859\n",
       "Name: RETURN_ON_ASSET, dtype: float64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()[\"RETURN_ON_ASSET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "db13a596-6e3e-40a7-861a-6e4a1da36c9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ASSET_TO_EQY', 'BS_CASH_NEAR_CASH_ITEM', 'BS_INVENTORIES',\n",
       "       'BS_OTHER_PPE_GROSS', 'BS_TOTAL_AVAIL_LINE_OF_CREDIT',\n",
       "       'BS_TOTAL_LIABILITIES', 'BS_TOT_ASSET', 'CASH_TO_TOT_ASSET',\n",
       "       'CFO_TO_TOT_DEBT', 'CF_FREE_CASH_FLOW', 'EBITDA_MARGIN',\n",
       "       'EBITDA_TO_REVENUE', 'EBITDA_TO_TOT_INT_EXP', 'FCF_TO_TOTAL_DEBT',\n",
       "       'IS_INT_EXPENSE', 'IS_NET_INTEREST_EXPENSE', 'RETURN_ON_ASSET',\n",
       "       'SALES_GROWTH', 'SALES_TO_INVENT', 'SALES_TO_TOT_ASSET',\n",
       "       'TANGIBLE_ASSETS', 'TOTAL_EQUITY', 'TOT_DEBT_TO_EBITDA',\n",
       "       'TOT_DEBT_TO_TOT_ASSET', 'TOT_DEBT_TO_TOT_EQY',\n",
       "       'TOTAL_DEBT_TO_TANGIBLE_ASSETS'],\n",
       "      dtype='object', name='Dates')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b802555-b785-486a-93ff-c1e83742c384",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fc846539-4262-48b7-bacc-e3aea12c896c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "debt_to_ebitda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "470164db-5b00-44a5-a303-304ac56bd78f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_loss(model_inputs):\n",
    "    yhat = []\n",
    "    for company in features.index:\n",
    "        ratios = features.loc[company][model_metrics].to_dict()    \n",
    "        model = CreditRatingCalculator(model_inputs)\n",
    "        model.calculate_credit_rating(ratios)\n",
    "\n",
    "        credit_score = model.credit_score\n",
    "        credit_rating = model.credit_rating\n",
    "\n",
    "        yhat.append(credit_score)\n",
    "\n",
    "    y_true = targets['numeric_rating']\n",
    "    yhat = np.round(yhat, 1)\n",
    "    loss = mean_absolute_percentage_error(yhat, y_true)\n",
    "    return loss\n",
    "\n",
    "def normalize_weights(weights):\n",
    "    total = sum(weights)\n",
    "    return [weight / total for weight in weights]\n",
    "\n",
    "def train_model(model_inputs, learning_rate=0.01, num_iterations=1000):\n",
    "    \n",
    "    np.random.seed(23)\n",
    "    \n",
    "    # Initialize weights and class_weights\n",
    "    for category in model_inputs.values():\n",
    "        category[\"class_weight\"] = np.random.random()\n",
    "        category[\"weights\"] = np.random.random(len(category[\"weights\"]))\n",
    "        category[\"weights\"] = normalize_weights(category[\"weights\"])\n",
    "\n",
    "    # Perform gradient descent\n",
    "    for epoch in range(num_iterations):\n",
    "        # Calculate gradients\n",
    "        gradients = {}\n",
    "        for category, category_data in model_inputs.items():\n",
    "            gradients[category] = {\n",
    "                \"class_weight\": 0.0,\n",
    "                \"weights\": np.zeros_like(category_data[\"weights\"])\n",
    "            }\n",
    "\n",
    "        # Calculate loss and gradients\n",
    "        loss = calculate_loss(model_inputs)\n",
    "        for category, category_data in model_inputs.items():\n",
    "            # Calculate gradient for class_weight\n",
    "            category_data[\"class_weight\"] += 0.0001\n",
    "            gradients[category][\"class_weight\"] = (calculate_loss(model_inputs) - loss) / 0.0001\n",
    "            category_data[\"class_weight\"] -= 0.0001\n",
    "\n",
    "            # Calculate gradients for weights\n",
    "            for i in range(len(category_data[\"weights\"])):\n",
    "                category_data[\"weights\"][i] += 0.0001\n",
    "                gradients[category][\"weights\"][i] = (calculate_loss(model_inputs) - loss) / 0.0001\n",
    "                category_data[\"weights\"][i] -= 0.0001\n",
    "\n",
    "        # Update weights and class_weights\n",
    "        for category, category_data in model_inputs.items():\n",
    "            category_data[\"class_weight\"] -= learning_rate * gradients[category][\"class_weight\"]\n",
    "            category_data[\"weights\"] -= learning_rate * gradients[category][\"weights\"]\n",
    "            category_data[\"weights\"] = normalize_weights(category_data[\"weights\"])\n",
    "\n",
    "        # Normalize class_weights\n",
    "        class_weights = [category_data[\"class_weight\"] for category_data in model_inputs.values()]\n",
    "        normalized_class_weights = normalize_weights(class_weights)\n",
    "        for category, weight in zip(model_inputs.keys(), normalized_class_weights):\n",
    "            model_inputs[category][\"class_weight\"] = weight\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
    "        \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "246abba0-eb49-415a-b06a-c30ab05a077a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 0.2761\n",
      "Epoch 100: Loss = 0.2593\n",
      "Epoch 200: Loss = 0.2593\n",
      "Category: profitability\n",
      "Class Weight: 0.367213686010887\n",
      "Weights: [1.0]\n",
      "\n",
      "Category: leverage_coverage\n",
      "Class Weight: 0.614510015986914\n",
      "Weights: [0.2373745964555163, 0.18580497915793837, 0.5768204243865455]\n",
      "\n",
      "Category: efficiency\n",
      "Class Weight: 0.018276298002199015\n",
      "Weights: [0.3883666310182689, 0.6116333689817312]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trained_model_inputs = train_model(model_inputs, learning_rate=0.1, num_iterations=300)\n",
    "\n",
    "# Print the optimized weights and class_weights\n",
    "for category, category_data in trained_model_inputs.items():\n",
    "    print(f\"Category: {category}\")\n",
    "    print(f\"Class Weight: {category_data['class_weight']}\")\n",
    "    print(f\"Weights: {category_data['weights']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6188c9dd-69dd-479d-a4c7-08096d4b2b4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def calculate_loss(model_inputs):\n",
    "    yhat = []\n",
    "    for company in features.index:\n",
    "        ratios = features.loc[company][model_metrics].to_dict()\n",
    "        model = CreditRatingCalculator(model_inputs)\n",
    "        model.calculate_credit_rating(ratios)\n",
    "        credit_score = model.credit_score\n",
    "        yhat.append(credit_score)\n",
    "    y_true = targets['numeric_rating']\n",
    "    yhat = np.round(yhat, 1)\n",
    "    loss = mean_absolute_percentage_error(yhat, y_true)\n",
    "    return loss\n",
    "\n",
    "def normalize_weights(weights):\n",
    "    total = sum(weights)\n",
    "    return [weight / total for weight in weights]\n",
    "\n",
    "def train_model(model_inputs, learning_rate=0.01, num_iterations=5000):\n",
    "    np.random.seed(23)\n",
    "    \n",
    "    # Initialize weights and class_weights\n",
    "    for category in model_inputs.values():\n",
    "        category[\"class_weight\"] = np.random.random()\n",
    "        category[\"weights\"] = np.random.random(len(category[\"weights\"]))\n",
    "        category[\"weights\"] = normalize_weights(category[\"weights\"])\n",
    "    \n",
    "    # Define the objective function for optimization\n",
    "    def objective(params):\n",
    "        idx = 0\n",
    "        for category in model_inputs.values():\n",
    "            category[\"class_weight\"] = params[idx]\n",
    "            idx += 1\n",
    "            category[\"weights\"] = params[idx:idx+len(category[\"weights\"])]\n",
    "            idx += len(category[\"weights\"])\n",
    "        return calculate_loss(model_inputs)\n",
    "    \n",
    "    # Define the bounds for optimization\n",
    "    bounds = []\n",
    "    for category in model_inputs.values():\n",
    "        bounds.append((0, 1))  # Class weight bounds\n",
    "        bounds.extend([(0, 1)] * len(category[\"weights\"]))  # Weight bounds\n",
    "    \n",
    "    # Perform optimization using L-BFGS-B\n",
    "    initial_params = []\n",
    "    for category in model_inputs.values():\n",
    "        initial_params.append(category[\"class_weight\"])\n",
    "        initial_params.extend(category[\"weights\"])\n",
    "    \n",
    "    result = minimize(objective, initial_params, method='L-BFGS-B', bounds=bounds, options={'maxiter': num_iterations})\n",
    "    print(result)\n",
    "    \n",
    "    # Update the optimized weights and class_weights\n",
    "    optimized_params = result.x\n",
    "    idx = 0\n",
    "    for category in model_inputs.values():\n",
    "        category[\"class_weight\"] = optimized_params[idx]\n",
    "        idx += 1\n",
    "        category[\"weights\"] = optimized_params[idx:idx+len(category[\"weights\"])]\n",
    "        idx += len(category[\"weights\"])\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "719c5e62-9792-476d-be61-1ec114e4dd55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m trained_model_inputs \u001b[38;5;241m=\u001b[39m train_model(model_inputs, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, num_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3000\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Print the optimized weights and class_weights\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m category, category_data \u001b[38;5;129;01min\u001b[39;00m trained_model_inputs\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_inputs' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trained_model_inputs = train_model(model_inputs, learning_rate=0.01, num_iterations=3000)\n",
    "\n",
    "# Print the optimized weights and class_weights\n",
    "for category, category_data in trained_model_inputs.items():\n",
    "    print(f\"Category: {category}\")\n",
    "    print(f\"Class Weight: {category_data['class_weight']}\")\n",
    "    print(f\"Weights: {category_data['weights']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa0b1c9-c74e-4d4e-9b39-869d91aa3478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316f90ec-8e31-4031-97a5-0edacc49145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model_inputs):\n",
    "    yhat = []\n",
    "    for company in features.index:\n",
    "        ratios = features.loc[company][model_metrics].to_dict()\n",
    "        model = CreditRatingCalculator(model_inputs)\n",
    "        model.calculate_credit_rating(ratios)\n",
    "        credit_score = model.credit_score\n",
    "        yhat.append(credit_score)\n",
    "    y_true = targets['numeric_rating']\n",
    "    yhat = np.round(yhat, 1)\n",
    "    loss = mean_absolute_percentage_error(yhat, y_true)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b581f5d0-2b38-46e6-9ff0-363c781ee842",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2592912997321396"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_loss(trained_model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae86c62-fa93-4621-8344-c86ecd7c4fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e69bd-0e91-4c5d-a5d0-416f8e8b2c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ba089a1-c201-4a2e-80c1-161b368c8e22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model_inputs, learning_rate=0.01, num_iterations=5000):\n",
    "    np.random.seed(23)\n",
    "    \n",
    "    # Initialize weights and class_weights\n",
    "    for category in model_inputs.values():\n",
    "        category[\"class_weight\"] = np.random.random()\n",
    "        category[\"weights\"] = np.random.random(len(category[\"weights\"]))\n",
    "        category[\"weights\"] = normalize_weights(category[\"weights\"])\n",
    "    \n",
    "    # Define the objective function for optimization\n",
    "    def objective(params):\n",
    "        idx = 0\n",
    "        for category in model_inputs.values():\n",
    "            category[\"class_weight\"] = params[idx]\n",
    "            idx += 1\n",
    "            category[\"weights\"] = params[idx:idx+len(category[\"weights\"])]\n",
    "            idx += len(category[\"weights\"])\n",
    "        return calculate_loss(model_inputs)\n",
    "    \n",
    "    # Define the bounds for optimization\n",
    "    bounds = []\n",
    "    for category in model_inputs.values():\n",
    "        bounds.append((0, 1))  # Class weight bounds\n",
    "        bounds.extend([(0, 1)] * len(category[\"weights\"]))  # Weight bounds\n",
    "    \n",
    "    # Perform optimization using L-BFGS-B\n",
    "    initial_params = []\n",
    "    for category in model_inputs.values():\n",
    "        initial_params.append(category[\"class_weight\"])\n",
    "        initial_params.extend(category[\"weights\"])\n",
    "    \n",
    "    result = minimize(objective, initial_params, method='L-BFGS-B', bounds=bounds, options={'maxiter': num_iterations})\n",
    "    \n",
    "    # Update the optimized weights and class_weights\n",
    "    optimized_params = result.x\n",
    "    idx = 0\n",
    "    for category in model_inputs.values():\n",
    "        category[\"class_weight\"] = optimized_params[idx]\n",
    "        idx += 1\n",
    "        category[\"weights\"] = optimized_params[idx:idx+len(category[\"weights\"])]\n",
    "        idx += len(category[\"weights\"])\n",
    "    \n",
    "    # Calculate and print the final error\n",
    "    final_error = calculate_loss(model_inputs)\n",
    "    print(f\"Final Error: {final_error:.4f}\")\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e47d3b9-5b76-47e0-8744-09d466bd1115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "15a5422d-cd85-4ed4-8396-a3f0b1cdfe9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_loss(model_inputs):\n",
    "    yhat = []\n",
    "    for company in features.index:\n",
    "        ratios = features.loc[company][model_metrics].to_dict()    \n",
    "        model = CreditRatingCalculator(model_inputs)\n",
    "        model.calculate_credit_rating(ratios)\n",
    "\n",
    "        credit_score = model.credit_score\n",
    "        credit_rating = model.credit_rating\n",
    "\n",
    "        yhat.append(credit_score)\n",
    "\n",
    "    y_true = targets['numeric_rating']\n",
    "    yhat = np.round(yhat, 1)\n",
    "    loss = mean_absolute_percentage_error(yhat, y_true)\n",
    "    print(y_true.values)\n",
    "    print(yhat)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "be71476e-1b9b-4fae-90ac-5be566aafe86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.5 5.5 4.5 6.5 4.5 5.5 6.5 4.5 6.5 6.5 7.5 5.5 5.5 6.5 5.5 5.5 6.5 6.5\n",
      " 5.5 6.5 5.5 6.5 5.5 6.5 6.5 6.5 6.5 6.5 5.5 8.5 6.5 6.5 6.5 6.5 6.5 6.5\n",
      " 6.5 6.5 6.5 6.5 6.5 6.5 6.5 6.5 6.5 6.5 5.5 6.5 5.5 6.5 6.5 6.5 6.5 6.5\n",
      " 6.5 6.5 6.5 5.5 6.5 6.5 7.5 6.5 6.5 5.5 5.5 6.5 6.5 5.5 6.5 6.5]\n",
      "[9.1 3.7 6.9 9.3 2.6 3.5 9.4 5.8 6.8 0.2 3.5 3.7 4.  0.2 3.5 9.2 0.2 7.\n",
      " 0.2 3.8 3.5 0.2 3.6 9.3 9.2 9.2 9.2 3.7 7.  9.3 0.2 5.7 9.  9.  9.4 2.4\n",
      " 3.8 3.8 4.6 8.1 8.  9.2 4.6 4.6 9.1 6.9 9.3 4.7 4.  6.9 9.1 3.8 3.7 3.7\n",
      " 3.7 0.3 4.6 4.1 9.2 6.9 6.9 9.  6.9 4.7 2.5 4.2 3.7 4.7 4.7 4.2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.305207936385858"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_loss(trained_model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "492bc020-39c5-4543-841b-31d933f03c51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-50.0, -37.5), (-37.5, -25.0), (-25.0, -12.5), (-12.5, 0.0), (0.0, 12.5), (12.5, 25.0), (25.0, 37.5), (37.5, 50.0), (37.5, 50)]\n"
     ]
    }
   ],
   "source": [
    "def get_buckets(min_val, max_val, lower_is_better=False, num_buckets=9):\n",
    "    \"\"\"\n",
    "    Generates optimized buckets based on min, max values, desired number of buckets, and whether lower values are better.\n",
    "\n",
    "    Args:\n",
    "        min_val (float): The minimum value.\n",
    "        max_val (float): The maximum value.\n",
    "        num_buckets (int, optional): Number of buckets. Defaults to 9.\n",
    "        lower_is_better (bool, optional): True if lower values are better, else False. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        list: List of tuples (start, end) representing each bucket's range.\n",
    "    \"\"\"\n",
    "    min_val, max_val = (max_val, min_val) if lower_is_better else (min_val, max_val)\n",
    "    interval = (max_val - min_val) / (num_buckets - 1)\n",
    "    buckets = [(round(min_val + i * interval, 2), round(min_val + (i + 1) * interval, 2)) for i in range(num_buckets - 1)]\n",
    "    buckets.append((round(max_val - interval, 2), max_val))\n",
    "    return list(reversed(buckets)) if lower_is_better else buckets\n",
    "\n",
    "\n",
    "# Redefine the values and number of buckets for clarity\n",
    "min_val = -50\n",
    "max_val = 50\n",
    "\n",
    "# Generate the optimized buckets\n",
    "buckets_list = get_buckets(min_val,  max_val)\n",
    "print(buckets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2d89e519-533f-4b92-994b-9f8ad8628bcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_val = features[model_metrics].max()\n",
    "min_val = features[model_metrics].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "47b17f9b-6bcc-45d1-8e4c-341543036eee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oper_margin [(-58.0, -42.75), (-42.75, -27.5), (-27.5, -12.25), (-12.25, 3.0), (3.0, 18.25), (18.25, 33.5), (33.5, 48.75), (48.75, 64.0), (48.75, 64.0)]\n",
      "tot_debt_to_tot_eqy [(4.0, 412.62), (412.62, 821.25), (821.25, 1229.88), (1229.88, 1638.5), (1638.5, 2047.12), (2047.12, 2455.75), (2455.75, 2864.38), (2864.38, 3273.0), (2864.38, 3273.0)]\n",
      "tot_debt_to_ebitda [(0.0, 7.62), (7.62, 15.25), (15.25, 22.88), (22.88, 30.5), (30.5, 38.12), (38.12, 45.75), (45.75, 53.38), (53.38, 61.0), (53.38, 61.0)]\n",
      "ebitda_to_tot_int_exp [(-1.0, 2.12), (2.12, 5.25), (5.25, 8.38), (8.38, 11.5), (11.5, 14.62), (14.62, 17.75), (17.75, 20.88), (20.88, 24.0), (20.88, 24.0)]\n",
      "return_on_asset [(-24.0, -18.38), (-18.38, -12.75), (-12.75, -7.12), (-7.12, -1.5), (-1.5, 4.12), (4.12, 9.75), (9.75, 15.38), (15.38, 21.0), (15.38, 21.0)]\n",
      "asset_turnover [(0.0, 0.5), (0.5, 1.0), (1.0, 1.5), (1.5, 2.0), (2.0, 2.5), (2.5, 3.0), (3.0, 3.5), (3.5, 4.0), (3.5, 4.0)]\n"
     ]
    }
   ],
   "source": [
    "for metric in model_metrics:\n",
    "    buckets = get_buckets(min_val.loc[metric].round(0), max_val.loc[metric].round(0))\n",
    "    print(metric, buckets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
