{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5bebd14-5939-4228-9449-e42827616343",
   "metadata": {},
   "source": [
    "# **Predictive Default Risk Assessor V.01**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa758ff1-aff3-4718-a6b6-2bf4aa81d71f",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* Base model \n",
    "* Comparison\n",
    "* Specialised\n",
    "* For small entities - Examples?\n",
    "* Backtest - All sectors \n",
    "* Understanding the model across all sectors/industries\n",
    "* Any markets - consumer goods, industries\n",
    "* UI last step after backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cebbf57d-65db-4819-98a2-b2ab40d50e03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import namedtuple\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, accuracy_score, mean_absolute_percentage_error\n",
    "from dataclasses import dataclass\n",
    "from quantstats import * \n",
    "extend_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bcae562-d34a-4fca-831c-d25dafd73948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = pd.read_excel(\"dataset/features.xlsx\", index_col=0)\n",
    "targets = pd.read_excel(\"dataset/target.xlsx\", index_col=0)\n",
    "features.columns = features.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "035b0334-ca7c-4bf8-befa-f56359d27fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "leverage_coverage_metrics = {\n",
    "    'class_weight': 20,\n",
    "    'metric_weights': {\n",
    "        'debt_to_equity': 0.2,\n",
    "        'debt_to_ebitda': 0.2,\n",
    "        'ebitda_to_interest_expense': 0.2,\n",
    "        'debt_to_tangible_assets': 0.4\n",
    "    },\n",
    "    'metrics': {\n",
    "        'debt_to_equity': {\n",
    "            'lower_is_better':True,\n",
    "            'thresholds':[\n",
    "                (float('-inf'), 0.25),\n",
    "                (0.25, 0.50),\n",
    "                (0.50, 0.75),\n",
    "                (0.75, 1.00),\n",
    "                (1.00, 1.50),\n",
    "                (1.50, 2.00),\n",
    "                (2.00, 3.00),\n",
    "                (3.00, 5.00),\n",
    "                (5.00, float('inf'))\n",
    "            ]\n",
    "        },\n",
    "        'debt_to_ebitda': {\n",
    "            'lower_is_better':True,\n",
    "            'thresholds':[\n",
    "                (float(\"-inf\"), 0.5),\n",
    "                (0.5, 1.0),\n",
    "                (1.0, 2.0),\n",
    "                (2.0, 3.0),\n",
    "                (3.0, 4.5),\n",
    "                (4.5, 6.5),\n",
    "                (6.5, 9.0),\n",
    "                (6.5, 9.0),\n",
    "                (9.0, float(\"inf\"))\n",
    "            ]\n",
    "        },\n",
    "        'ebitda_to_interest_expense': {\n",
    "            'lower_is_better':False,\n",
    "            'thresholds':[\n",
    "                (25.0, float(\"inf\")),\n",
    "                (15.0, 25.0),\n",
    "                (10.0, 15.0),\n",
    "                (6.0, 10.0),\n",
    "                (3.0, 6.0),\n",
    "                (1.0, 3.0),\n",
    "                (0.0, 1.0),\n",
    "                (0.0, 1.0),\n",
    "                (float(\"-inf\"), 0.0)\n",
    "            ]\n",
    "        },\n",
    "        'debt_to_tangible_assets': {\n",
    "            'lower_is_better':True,\n",
    "            'thresholds':[\n",
    "                (float('-inf'), 0.20),\n",
    "                (0.20, 0.40),\n",
    "                (0.40, 0.60),\n",
    "                (0.60, 0.80),\n",
    "                (0.80, 1.00),\n",
    "                (1.00, 1.20),\n",
    "                (1.20, 1.50),\n",
    "                (1.50, 2.00),\n",
    "                (2.00, float('inf'))\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "efficiency_metrics = {\n",
    "    'class_weight': 15,\n",
    "    'metric_weights': {\n",
    "        'asset_turnover': 0.4,\n",
    "        'inventory_to_cost_of_sales': 0.3,\n",
    "        'cash_to_assets': 0.3\n",
    "    },\n",
    "    'metrics': {\n",
    "        'asset_turnover': {\n",
    "            'lower_is_better':False,\n",
    "            'thresholds':[\n",
    "                (5.00, float('inf')),\n",
    "                (4.00, 5.00),\n",
    "                (3.00, 4.00),\n",
    "                (2.50, 3.00),\n",
    "                (2.00, 2.50),\n",
    "                (1.50, 2.00),\n",
    "                (1.00, 1.50),\n",
    "                (0.50, 1.00),\n",
    "                (float('-inf'), 0.50)\n",
    "            ]\n",
    "        },\n",
    "        'inventory_to_cost_of_sales': {\n",
    "            'lower_is_better':True,\n",
    "            'thresholds':[\n",
    "                (float('-inf'), 0.10),\n",
    "                (0.10, 0.20),\n",
    "                (0.20, 0.30),\n",
    "                (0.30, 0.40),\n",
    "                (0.40, 0.50),\n",
    "                (0.50, 0.60),\n",
    "                (0.60, 0.80),\n",
    "                (0.80, 1.00),\n",
    "                (1.00, float('inf'))\n",
    "            ]\n",
    "        },\n",
    "        'cash_to_assets': {\n",
    "            'lower_is_better':False,\n",
    "            'thresholds':[\n",
    "                (0.50, float('inf')),\n",
    "                (0.40, 0.50),\n",
    "                (0.30, 0.40),\n",
    "                (0.25, 0.30),\n",
    "                (0.20, 0.25),\n",
    "                (0.15, 0.20),\n",
    "                (0.10, 0.15),\n",
    "                (0.05, 0.10),\n",
    "                (float('-inf'), 0.05)\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "profitability_metrics = {\n",
    "    'class_weight': 25,\n",
    "    'metric_weights': {\n",
    "        'ebitda_margin': 0.4,\n",
    "        'total_assets': 0.3,\n",
    "        'sales_growth': 0.3\n",
    "    },\n",
    "    'metrics': {\n",
    "        'ebitda_margin': {\n",
    "            'lower_is_better':False,\n",
    "            'thresholds':[\n",
    "                (40.0, float('inf')), \n",
    "                (35.0, 40.0), \n",
    "                (30.0, 35.0),\n",
    "                (25.0, 30.0), \n",
    "                (20.0, 25.0), \n",
    "                (15.0, 20.0),\n",
    "                (10.0, 15.0), \n",
    "                (5.0, 10.0), \n",
    "                (float('-inf'), 5.0)\n",
    "            ]\n",
    "        },\n",
    "        'total_assets': {\n",
    "            'lower_is_better':False,\n",
    "            'thresholds':[\n",
    "                (500_000_000, float('inf')), \n",
    "                (100_000_000, 500_000_000), \n",
    "                (50_000_000, 100_000_000),\n",
    "                (10_000_000, 50_000_000), \n",
    "                (5_000_000, 10_000_000), \n",
    "                (1_000_000, 5_000_000),\n",
    "                (500_000, 1_000_000), \n",
    "                (100_000, 500_000), \n",
    "                (float('-inf'), 100_000)\n",
    "            ]\n",
    "        },\n",
    "        'sales_growth': {\n",
    "            'lower_is_better':False,\n",
    "            'thresholds':[\n",
    "                (40.0, float('inf')), \n",
    "                (30.0, 40.0), \n",
    "                (25.0, 30.0),\n",
    "                (20.0, 25.0), \n",
    "                (15.0, 20.0), \n",
    "                (10.0, 15.0),\n",
    "                (5.0, 10.0), \n",
    "                (0.0, 5.0), \n",
    "                (float('-inf'), 0.0)\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0285421d-90d2-4e31-930e-068f8a1f7901",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "financial_metrics = {\n",
    "    'profitability_metrics':profitability_metrics,\n",
    "    'leverage_coverage_metrics': leverage_coverage_metrics,\n",
    "    'efficiency_metrics': efficiency_metrics\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddcf4d00-63ef-4711-8b07-b2a2892b6a69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CreditRatingCalculator:\n",
    "    def __init__(self, metrics):\n",
    "        self.metrics = metrics\n",
    "        self.calculation_details = {\"metrics\": {}}\n",
    "\n",
    "    def _calculate_metric_score(self, value, thresholds, inverse):\n",
    "        for score, (lower, upper) in enumerate(thresholds, start=1):\n",
    "            if inverse and value <= upper or not inverse and value >= lower:\n",
    "                return score\n",
    "        return len(thresholds) // 2\n",
    "\n",
    "    def _determine_credit_rating(self, score):\n",
    "        credit_ratings = [\n",
    "            (\"Aaa\", 2.5),\n",
    "            (\"Aa\", 3.5),\n",
    "            (\"A\", 4.5),\n",
    "            (\"Baa\", 5.5),\n",
    "            (\"Ba\", 6.5),\n",
    "            (\"B\", 7.5),\n",
    "            (\"Caa\", 8.5),\n",
    "            (\"Ca\", 9.5),\n",
    "            (\"C\", float(\"inf\")),\n",
    "        ]\n",
    "        for rating, threshold in credit_ratings:\n",
    "            if score <= threshold:\n",
    "                return rating\n",
    "\n",
    "    def _calculate_category_score(self, category, category_data):\n",
    "        category_ratios = self.ratios[category]\n",
    "        metric_weights = category_data[\"metric_weights\"]\n",
    "        total_weighted_score = 0\n",
    "\n",
    "        for metric_name, metric_data in category_data[\"metrics\"].items():\n",
    "            value = category_ratios[metric_name]\n",
    "            score = self._calculate_metric_score(value, metric_data[\"thresholds\"], metric_data[\"lower_is_better\"])\n",
    "            weight = metric_weights[metric_name]\n",
    "            weighted_score = score * weight\n",
    "            rating = self._determine_credit_rating(score)\n",
    "            total_weighted_score += weighted_score\n",
    "\n",
    "            self.calculation_details[\"metrics\"][metric_name] = {\n",
    "                \"category\": category,\n",
    "                \"value\": value,\n",
    "                \"score\": score,\n",
    "                \"weight\": weight,\n",
    "                \"weighted_score\": weighted_score,\n",
    "                \"rating\": rating,\n",
    "            }\n",
    "\n",
    "        return total_weighted_score\n",
    "\n",
    "    def _calculate_scores(self):\n",
    "        return {category: self._calculate_category_score(category, category_data)\n",
    "                for category, category_data in self.metrics.items()}\n",
    "\n",
    "    def _calculate_weighted_score(self, scores):\n",
    "        total_weighted_score = sum(\n",
    "            scores[category] * category_data[\"class_weight\"]\n",
    "            for category, category_data in self.metrics.items()\n",
    "        )\n",
    "        total_weight = sum(category_data[\"class_weight\"] for category_data in self.metrics.values())\n",
    "        return total_weighted_score / total_weight\n",
    "\n",
    "    def calculate_credit_rating(self, ratios):\n",
    "        self.ratios = ratios\n",
    "        scores = self._calculate_scores()\n",
    "        credit_score = self._calculate_weighted_score(scores)\n",
    "        credit_rating = self._determine_credit_rating(credit_score)\n",
    "\n",
    "        self.calculation_details.update({\n",
    "            \"scores\": scores,\n",
    "            \"credit_score\": credit_score,\n",
    "            \"credit_rating\": credit_rating,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d43aff10-e89c-4cc7-8705-046f31760739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_expected_metrics(data):\n",
    "    return {\n",
    "        category: {metric: sum(values) / len(values) \n",
    "        for metric, values in metrics.items()}\n",
    "        for category, metrics in data.items()\n",
    "    }\n",
    "\n",
    "def get_nested_dict(data):\n",
    "    nested_dict = {}\n",
    "\n",
    "    for (category, metric), values in data.iterrows():\n",
    "        if category not in nested_dict:\n",
    "            nested_dict[category] = {}\n",
    "        nested_dict[category][metric] = values.tolist()\n",
    "\n",
    "    return nested_dict\n",
    "\n",
    "def get_period_metrics(data):\n",
    "    n = len(data['leverage_coverage_metrics']['debt_to_equity'])\n",
    "    return {\n",
    "        i: {\n",
    "            category: {metric: values[i] \n",
    "            for metric, values in metrics.items()}\n",
    "            for category, metrics in data.items()\n",
    "        }\n",
    "        for i in range(n)\n",
    "    }\n",
    "\n",
    "\n",
    "def bayesian_ridge_model(metrics, periods=1, max_iter=300, tol=1e-3):\n",
    "    import numpy as np\n",
    "    from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "    predictions = {}\n",
    "    for metric_group, values_dict in metrics.items():\n",
    "        predictions[metric_group] = {}\n",
    "        for metric, values in values_dict.items():\n",
    "            X = np.arange(len(values)).reshape(-1, 1)\n",
    "            \n",
    "            model = BayesianRidge(max_iter=max_iter, tol=tol).fit(X, values)\n",
    "            \n",
    "            next_periods = np.arange(len(values), len(values) + periods).reshape(-1, 1)\n",
    "            predictions[metric_group][metric] = model.predict(next_periods).tolist() if periods > 0 else list(values)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3152654a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the data\n",
    "data = { \n",
    "    ('leverage_coverage_metrics', 'debt_to_equity'): [1.2, 1.0, 1.3, 1.2], \n",
    "    ('leverage_coverage_metrics', 'debt_to_ebitda'): [3.5, 3.6, 3.4, 3.5], \n",
    "    ('leverage_coverage_metrics', 'ebitda_to_interest_expense'): [8.0, 7.5, 8.2, 8.0], \n",
    "    ('leverage_coverage_metrics', 'debt_to_tangible_assets'): [0.6, 0.7, 0.5, 0.6], \n",
    "    ('efficiency_metrics', 'asset_turnover'): [1.8, 1.7, 1.9, 1.8], \n",
    "    ('efficiency_metrics', 'inventory_to_cost_of_sales'): [0.4, 0.5, 0.3, 0.4], \n",
    "    ('efficiency_metrics', 'cash_to_assets'): [0.2, 0.25, 0.15, 0.2], \n",
    "    ('profitability_metrics', 'ebitda_margin'): [18.0, 19.0, 17.5, 18.0], \n",
    "    ('profitability_metrics', 'total_assets'): [50000000, 52000000, 51000000, 50000000], \n",
    "    ('profitability_metrics', 'sales_growth'): [12.0, 13.0, 11.5, 12.0],\n",
    "}\n",
    "\n",
    "# Create a multi-index DataFrame\n",
    "index = pd.MultiIndex.from_tuples(data.keys(), names=['Metric Category', 'Metric Name'])\n",
    "df = pd.DataFrame(data.values(), index=index, columns=['Q1', 'Q2', 'Q3', 'Q4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "578a1241-1d33-4ac3-b2b7-a0b1fa7370c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rating_description_dict = {\n",
    "    \"Aaa\": \"Issuers assessed Aaa are judged to have the highest intrinsic, or standalone, financial strength, and thus subject to the lowest level of credit risk absent any possibility of extraordinary support from an affiliate or a government.\",\n",
    "    \"Aa\": \"Issuers assessed Aa are judged to have high intrinsic, or standalone, financial strength, and thus subject to very low credit risk absent any possibility of extraordinary support from an affiliate or a government.\",\n",
    "    \"A\": \"Issuers assessed A are judged to have upper-medium-grade intrinsic, or standalone, financial strength, and thus subject to low credit risk absent any possibility of extraordinary support from an affiliate or a government.\",\n",
    "    \"Baa\": \"Issuers assessed Baa are judged to have medium-grade intrinsic, or standalone, financial strength, and thus subject to moderate credit risk and, as such, may possess certain speculative credit elements absent any possibility of extraordinary support from an affiliate or a government.\",\n",
    "    \"Ba\": \"Issuers assessed Ba are judged to have speculative intrinsic, or standalone, financial strength, and are subject to substantial credit risk absent any possibility of extraordinary support from an affiliate or a government.\",\n",
    "    \"B\": \"Issuers assessed B are judged to have speculative intrinsic, or standalone, financial strength, and are subject to high credit risk absent any possibility of extraordinary support from an affiliate or a government.\",\n",
    "    \"Caa\": \"Issuers assessed Caa are judged to have speculative intrinsic, or standalone, financial strength, and are subject to very high credit risk absent any possibility of extraordinary support from an affiliate or a government.\",\n",
    "    \"Ca\": \"Issuers assessed Ca have highly speculative intrinsic, or standalone, financial strength, and are likely to be either in, or very near, default, with some prospect for recovery of principal and interest; or, these issuers have avoided default or are expected to avoid default through the provision of extraordinary support from an affiliate or a government.\",\n",
    "    \"C\": \"Issuers assessed C are typically in default, with little prospect for recovery of principal or interest; or, these issuers are benefiting from a government or affiliate support but are likely to be liquidated over time; without support there would be little prospect for recovery of principal or interest.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b828b85-48e6-45cf-bc9e-92f7c0f39d13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class HelloCredit:\n",
    "    file_path: str = None\n",
    "    metrics_path: str = None\n",
    "    \n",
    "    def __post_init__(self):        \n",
    "        self.file_path = self.file_path or \"data.xlsx\"\n",
    "        self.metrics_path = self.metrics_path or \"metrics.json\"\n",
    "        \n",
    "        with open(self.metrics_path, \"r\") as f:\n",
    "            self.metrics = json.load(f)\n",
    "            \n",
    "        self.class_weights = {m: self.metrics[m][\"class_weight\"] for m in self.metrics}\n",
    "        self.dataframe = pd.read_excel(self.file_path, index_col=[0, 1])\n",
    "        self.nested_dict = get_nested_dict(self.dataframe)\n",
    "        self.company_period_metrics = get_period_metrics(self.nested_dict)\n",
    "        self.company_expected_metrics = get_expected_metrics(self.nested_dict)\n",
    "        self.input_dict = {\n",
    "            \"company_name\": None,\n",
    "            \"calculator_model\": {\"sector\": \"Corporates\", \"size\": \"Small\"},\n",
    "            \"factor_weights_model\": self.class_weights,\n",
    "            \"probabilistic_model\": {\"periods\": 1, \"max_iter\": 300, \"tol\": 1e-3}\n",
    "        }\n",
    "\n",
    "    \n",
    "    \n",
    "    def update_input_dict(self, input_dict: dict) -> dict:  \n",
    "        def deep_update(d, u):\n",
    "            for k, v in u.items():\n",
    "                if isinstance(v, dict):\n",
    "                    d[k] = deep_update(d.get(k, {}), v)\n",
    "                else:\n",
    "                    d[k] = v\n",
    "            return d\n",
    "\n",
    "        self.input_dict = deep_update(self.input_dict, input_dict)\n",
    "    \n",
    "    \n",
    "    def update_output_dict(self):\n",
    "        calculator = CreditRatingCalculator(self.metrics)\n",
    "        calculator.calculate_credit_rating(self.company_expected_metrics)\n",
    "        calculator_output = calculator.calculation_details\n",
    "\n",
    "        # Single Period Calcs\n",
    "        calculator_periods_output = {}\n",
    "        for period in self.company_period_metrics:\n",
    "            calculator = CreditRatingCalculator(self.metrics)\n",
    "            calculator.calculate_credit_rating(self.company_period_metrics[period])\n",
    "            calculator_periods_output[period] = calculator.calculation_details\n",
    "\n",
    "        # Bayesian Model\n",
    "        bayesian_model_output = bayesian_ridge_model(self.nested_dict, **self.input_dict[\"probabilistic_model\"])\n",
    "\n",
    "        # Rating Description\n",
    "        rating_description = rating_description_dict[calculator_output[\"credit_rating\"]]\n",
    "\n",
    "        output_dict = {\n",
    "            \"company_name\": self.input_dict[\"company_name\"],\n",
    "            \"rating_description\": rating_description,\n",
    "            \"company_expected_metrics\": self.company_expected_metrics,\n",
    "            \"company_period_metrics\": self.company_period_metrics,\n",
    "            \"calculator_output\": calculator_output,\n",
    "            \"calculator_periods_output\": calculator_periods_output,\n",
    "            \"bayesian_model_output\": bayesian_model_output,\n",
    "            \"metrics\": self.metrics\n",
    "        }\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a07e376-3dac-417d-9b4b-95b5682ea6ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = HelloCredit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24138eac-7dd3-434f-bebd-66b45eb8921e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m.update_input_dict({\"probabilistic_model\": {\"periods\": 10}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41aeee7-a618-43e4-82a9-63002f232ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc92c3f-87f8-4a99-800f-576b9ac23dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ae4c4-6085-44f8-b78b-0b6a9fefe655",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59661e1b-a1cf-4947-9849-626cce7da466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9512b38c-cbeb-4fbd-8ce7-0b68718f9684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd587a7-6235-40d8-9fb9-c46b274b79f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08221e9-3747-4770-956f-d325b0425fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6399135-9803-43e0-8473-e80c2ba5eb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a8e03d-29ac-4cf4-83a1-8ee9e79547dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e58c32-2886-4881-8769-b15dc51b4fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a330dc-e8b7-49f7-ad97-84cfebea24c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e029b1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb54d04-dfe2-4b08-885a-bdca611cacf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ef8c91-1039-4487-afcc-5cda5a6de616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67abcec1-95b2-423d-a9c6-76bb8975b6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b802555-b785-486a-93ff-c1e83742c384",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "470164db-5b00-44a5-a303-304ac56bd78f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_loss(model_inputs):\n",
    "    yhat = []\n",
    "    for company in features.index:\n",
    "        ratios = features.loc[company][model_metrics].to_dict()    \n",
    "        model = CreditRatingCalculator(model_inputs)\n",
    "        model.calculate_credit_rating(ratios)\n",
    "\n",
    "        credit_score = model.credit_score\n",
    "        credit_rating = model.credit_rating\n",
    "\n",
    "        yhat.append(credit_score)\n",
    "\n",
    "    y_true = targets['numeric_rating']\n",
    "    yhat = np.round(yhat, 1)\n",
    "    loss = mean_absolute_percentage_error(yhat, y_true)\n",
    "    return loss\n",
    "\n",
    "def normalize_weights(weights):\n",
    "    total = sum(weights)\n",
    "    return [weight / total for weight in weights]\n",
    "\n",
    "def train_model(model_inputs, learning_rate=0.01, num_iterations=1000):\n",
    "    \n",
    "    np.random.seed(23)\n",
    "    \n",
    "    # Initialize weights and class_weights\n",
    "    for category in model_inputs.values():\n",
    "        category[\"class_weight\"] = np.random.random()\n",
    "        category[\"weights\"] = np.random.random(len(category[\"weights\"]))\n",
    "        category[\"weights\"] = normalize_weights(category[\"weights\"])\n",
    "\n",
    "    # Perform gradient descent\n",
    "    for epoch in range(num_iterations):\n",
    "        # Calculate gradients\n",
    "        gradients = {}\n",
    "        for category, category_data in model_inputs.items():\n",
    "            gradients[category] = {\n",
    "                \"class_weight\": 0.0,\n",
    "                \"weights\": np.zeros_like(category_data[\"weights\"])\n",
    "            }\n",
    "\n",
    "        # Calculate loss and gradients\n",
    "        loss = calculate_loss(model_inputs)\n",
    "        for category, category_data in model_inputs.items():\n",
    "            # Calculate gradient for class_weight\n",
    "            category_data[\"class_weight\"] += 0.0001\n",
    "            gradients[category][\"class_weight\"] = (calculate_loss(model_inputs) - loss) / 0.0001\n",
    "            category_data[\"class_weight\"] -= 0.0001\n",
    "\n",
    "            # Calculate gradients for weights\n",
    "            for i in range(len(category_data[\"weights\"])):\n",
    "                category_data[\"weights\"][i] += 0.0001\n",
    "                gradients[category][\"weights\"][i] = (calculate_loss(model_inputs) - loss) / 0.0001\n",
    "                category_data[\"weights\"][i] -= 0.0001\n",
    "\n",
    "        # Update weights and class_weights\n",
    "        for category, category_data in model_inputs.items():\n",
    "            category_data[\"class_weight\"] -= learning_rate * gradients[category][\"class_weight\"]\n",
    "            category_data[\"weights\"] -= learning_rate * gradients[category][\"weights\"]\n",
    "            category_data[\"weights\"] = normalize_weights(category_data[\"weights\"])\n",
    "\n",
    "        # Normalize class_weights\n",
    "        class_weights = [category_data[\"class_weight\"] for category_data in model_inputs.values()]\n",
    "        normalized_class_weights = normalize_weights(class_weights)\n",
    "        for category, weight in zip(model_inputs.keys(), normalized_class_weights):\n",
    "            model_inputs[category][\"class_weight\"] = weight\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
    "        \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "246abba0-eb49-415a-b06a-c30ab05a077a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 0.2761\n",
      "Epoch 100: Loss = 0.2593\n",
      "Epoch 200: Loss = 0.2593\n",
      "Category: profitability\n",
      "Class Weight: 0.367213686010887\n",
      "Weights: [1.0]\n",
      "\n",
      "Category: leverage_coverage\n",
      "Class Weight: 0.614510015986914\n",
      "Weights: [0.2373745964555163, 0.18580497915793837, 0.5768204243865455]\n",
      "\n",
      "Category: efficiency\n",
      "Class Weight: 0.018276298002199015\n",
      "Weights: [0.3883666310182689, 0.6116333689817312]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trained_model_inputs = train_model(model_inputs, learning_rate=0.1, num_iterations=300)\n",
    "\n",
    "# Print the optimized weights and class_weights\n",
    "for category, category_data in trained_model_inputs.items():\n",
    "    print(f\"Category: {category}\")\n",
    "    print(f\"Class Weight: {category_data['class_weight']}\")\n",
    "    print(f\"Weights: {category_data['weights']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6188c9dd-69dd-479d-a4c7-08096d4b2b4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def calculate_loss(model_inputs):\n",
    "    yhat = []\n",
    "    for company in features.index:\n",
    "        ratios = features.loc[company][model_metrics].to_dict()\n",
    "        model = CreditRatingCalculator(model_inputs)\n",
    "        model.calculate_credit_rating(ratios)\n",
    "        credit_score = model.credit_score\n",
    "        yhat.append(credit_score)\n",
    "    y_true = targets['numeric_rating']\n",
    "    yhat = np.round(yhat, 1)\n",
    "    loss = mean_absolute_percentage_error(yhat, y_true)\n",
    "    return loss\n",
    "\n",
    "def normalize_weights(weights):\n",
    "    total = sum(weights)\n",
    "    return [weight / total for weight in weights]\n",
    "\n",
    "def train_model(model_inputs, learning_rate=0.01, num_iterations=5000):\n",
    "    np.random.seed(23)\n",
    "    \n",
    "    # Initialize weights and class_weights\n",
    "    for category in model_inputs.values():\n",
    "        category[\"class_weight\"] = np.random.random()\n",
    "        category[\"weights\"] = np.random.random(len(category[\"weights\"]))\n",
    "        category[\"weights\"] = normalize_weights(category[\"weights\"])\n",
    "    \n",
    "    # Define the objective function for optimization\n",
    "    def objective(params):\n",
    "        idx = 0\n",
    "        for category in model_inputs.values():\n",
    "            category[\"class_weight\"] = params[idx]\n",
    "            idx += 1\n",
    "            category[\"weights\"] = params[idx:idx+len(category[\"weights\"])]\n",
    "            idx += len(category[\"weights\"])\n",
    "        return calculate_loss(model_inputs)\n",
    "    \n",
    "    # Define the bounds for optimization\n",
    "    bounds = []\n",
    "    for category in model_inputs.values():\n",
    "        bounds.append((0, 1))  # Class weight bounds\n",
    "        bounds.extend([(0, 1)] * len(category[\"weights\"]))  # Weight bounds\n",
    "    \n",
    "    # Perform optimization using L-BFGS-B\n",
    "    initial_params = []\n",
    "    for category in model_inputs.values():\n",
    "        initial_params.append(category[\"class_weight\"])\n",
    "        initial_params.extend(category[\"weights\"])\n",
    "    \n",
    "    result = minimize(objective, initial_params, method='L-BFGS-B', bounds=bounds, options={'maxiter': num_iterations})\n",
    "    print(result)\n",
    "    \n",
    "    # Update the optimized weights and class_weights\n",
    "    optimized_params = result.x\n",
    "    idx = 0\n",
    "    for category in model_inputs.values():\n",
    "        category[\"class_weight\"] = optimized_params[idx]\n",
    "        idx += 1\n",
    "        category[\"weights\"] = optimized_params[idx:idx+len(category[\"weights\"])]\n",
    "        idx += len(category[\"weights\"])\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "719c5e62-9792-476d-be61-1ec114e4dd55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m trained_model_inputs \u001b[38;5;241m=\u001b[39m train_model(model_inputs, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, num_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3000\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Print the optimized weights and class_weights\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m category, category_data \u001b[38;5;129;01min\u001b[39;00m trained_model_inputs\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_inputs' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trained_model_inputs = train_model(model_inputs, learning_rate=0.01, num_iterations=3000)\n",
    "\n",
    "# Print the optimized weights and class_weights\n",
    "for category, category_data in trained_model_inputs.items():\n",
    "    print(f\"Category: {category}\")\n",
    "    print(f\"Class Weight: {category_data['class_weight']}\")\n",
    "    print(f\"Weights: {category_data['weights']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa0b1c9-c74e-4d4e-9b39-869d91aa3478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316f90ec-8e31-4031-97a5-0edacc49145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model_inputs):\n",
    "    yhat = []\n",
    "    for company in features.index:\n",
    "        ratios = features.loc[company][model_metrics].to_dict()\n",
    "        model = CreditRatingCalculator(model_inputs)\n",
    "        model.calculate_credit_rating(ratios)\n",
    "        credit_score = model.credit_score\n",
    "        yhat.append(credit_score)\n",
    "    y_true = targets['numeric_rating']\n",
    "    yhat = np.round(yhat, 1)\n",
    "    loss = mean_absolute_percentage_error(yhat, y_true)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b581f5d0-2b38-46e6-9ff0-363c781ee842",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2592912997321396"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_loss(trained_model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae86c62-fa93-4621-8344-c86ecd7c4fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e69bd-0e91-4c5d-a5d0-416f8e8b2c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ba089a1-c201-4a2e-80c1-161b368c8e22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model_inputs, learning_rate=0.01, num_iterations=5000):\n",
    "    np.random.seed(23)\n",
    "    \n",
    "    # Initialize weights and class_weights\n",
    "    for category in model_inputs.values():\n",
    "        category[\"class_weight\"] = np.random.random()\n",
    "        category[\"weights\"] = np.random.random(len(category[\"weights\"]))\n",
    "        category[\"weights\"] = normalize_weights(category[\"weights\"])\n",
    "    \n",
    "    # Define the objective function for optimization\n",
    "    def objective(params):\n",
    "        idx = 0\n",
    "        for category in model_inputs.values():\n",
    "            category[\"class_weight\"] = params[idx]\n",
    "            idx += 1\n",
    "            category[\"weights\"] = params[idx:idx+len(category[\"weights\"])]\n",
    "            idx += len(category[\"weights\"])\n",
    "        return calculate_loss(model_inputs)\n",
    "    \n",
    "    # Define the bounds for optimization\n",
    "    bounds = []\n",
    "    for category in model_inputs.values():\n",
    "        bounds.append((0, 1))  # Class weight bounds\n",
    "        bounds.extend([(0, 1)] * len(category[\"weights\"]))  # Weight bounds\n",
    "    \n",
    "    # Perform optimization using L-BFGS-B\n",
    "    initial_params = []\n",
    "    for category in model_inputs.values():\n",
    "        initial_params.append(category[\"class_weight\"])\n",
    "        initial_params.extend(category[\"weights\"])\n",
    "    \n",
    "    result = minimize(objective, initial_params, method='L-BFGS-B', bounds=bounds, options={'maxiter': num_iterations})\n",
    "    \n",
    "    # Update the optimized weights and class_weights\n",
    "    optimized_params = result.x\n",
    "    idx = 0\n",
    "    for category in model_inputs.values():\n",
    "        category[\"class_weight\"] = optimized_params[idx]\n",
    "        idx += 1\n",
    "        category[\"weights\"] = optimized_params[idx:idx+len(category[\"weights\"])]\n",
    "        idx += len(category[\"weights\"])\n",
    "    \n",
    "    # Calculate and print the final error\n",
    "    final_error = calculate_loss(model_inputs)\n",
    "    print(f\"Final Error: {final_error:.4f}\")\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e47d3b9-5b76-47e0-8744-09d466bd1115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "15a5422d-cd85-4ed4-8396-a3f0b1cdfe9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_loss(model_inputs):\n",
    "    yhat = []\n",
    "    for company in features.index:\n",
    "        ratios = features.loc[company][model_metrics].to_dict()    \n",
    "        model = CreditRatingCalculator(model_inputs)\n",
    "        model.calculate_credit_rating(ratios)\n",
    "\n",
    "        credit_score = model.credit_score\n",
    "        credit_rating = model.credit_rating\n",
    "\n",
    "        yhat.append(credit_score)\n",
    "\n",
    "    y_true = targets['numeric_rating']\n",
    "    yhat = np.round(yhat, 1)\n",
    "    loss = mean_absolute_percentage_error(yhat, y_true)\n",
    "    print(y_true.values)\n",
    "    print(yhat)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "be71476e-1b9b-4fae-90ac-5be566aafe86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.5 5.5 4.5 6.5 4.5 5.5 6.5 4.5 6.5 6.5 7.5 5.5 5.5 6.5 5.5 5.5 6.5 6.5\n",
      " 5.5 6.5 5.5 6.5 5.5 6.5 6.5 6.5 6.5 6.5 5.5 8.5 6.5 6.5 6.5 6.5 6.5 6.5\n",
      " 6.5 6.5 6.5 6.5 6.5 6.5 6.5 6.5 6.5 6.5 5.5 6.5 5.5 6.5 6.5 6.5 6.5 6.5\n",
      " 6.5 6.5 6.5 5.5 6.5 6.5 7.5 6.5 6.5 5.5 5.5 6.5 6.5 5.5 6.5 6.5]\n",
      "[9.1 3.7 6.9 9.3 2.6 3.5 9.4 5.8 6.8 0.2 3.5 3.7 4.  0.2 3.5 9.2 0.2 7.\n",
      " 0.2 3.8 3.5 0.2 3.6 9.3 9.2 9.2 9.2 3.7 7.  9.3 0.2 5.7 9.  9.  9.4 2.4\n",
      " 3.8 3.8 4.6 8.1 8.  9.2 4.6 4.6 9.1 6.9 9.3 4.7 4.  6.9 9.1 3.8 3.7 3.7\n",
      " 3.7 0.3 4.6 4.1 9.2 6.9 6.9 9.  6.9 4.7 2.5 4.2 3.7 4.7 4.7 4.2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.305207936385858"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_loss(trained_model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "492bc020-39c5-4543-841b-31d933f03c51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-50.0, -37.5), (-37.5, -25.0), (-25.0, -12.5), (-12.5, 0.0), (0.0, 12.5), (12.5, 25.0), (25.0, 37.5), (37.5, 50.0), (37.5, 50)]\n"
     ]
    }
   ],
   "source": [
    "def get_buckets(min_val, max_val, lower_is_better=False, num_buckets=9):\n",
    "    \"\"\"\n",
    "    Generates optimized buckets based on min, max values, desired number of buckets, and whether lower values are better.\n",
    "\n",
    "    Args:\n",
    "        min_val (float): The minimum value.\n",
    "        max_val (float): The maximum value.\n",
    "        num_buckets (int, optional): Number of buckets. Defaults to 9.\n",
    "        lower_is_better (bool, optional): True if lower values are better, else False. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        list: List of tuples (start, end) representing each bucket's range.\n",
    "    \"\"\"\n",
    "    min_val, max_val = (max_val, min_val) if lower_is_better else (min_val, max_val)\n",
    "    interval = (max_val - min_val) / (num_buckets - 1)\n",
    "    buckets = [(round(min_val + i * interval, 2), round(min_val + (i + 1) * interval, 2)) for i in range(num_buckets - 1)]\n",
    "    buckets.append((round(max_val - interval, 2), max_val))\n",
    "    return list(reversed(buckets)) if lower_is_better else buckets\n",
    "\n",
    "\n",
    "# Redefine the values and number of buckets for clarity\n",
    "min_val = -50\n",
    "max_val = 50\n",
    "\n",
    "# Generate the optimized buckets\n",
    "buckets_list = get_buckets(min_val,  max_val)\n",
    "print(buckets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2d89e519-533f-4b92-994b-9f8ad8628bcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_val = features[model_metrics].max()\n",
    "min_val = features[model_metrics].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "47b17f9b-6bcc-45d1-8e4c-341543036eee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oper_margin [(-58.0, -42.75), (-42.75, -27.5), (-27.5, -12.25), (-12.25, 3.0), (3.0, 18.25), (18.25, 33.5), (33.5, 48.75), (48.75, 64.0), (48.75, 64.0)]\n",
      "tot_debt_to_tot_eqy [(4.0, 412.62), (412.62, 821.25), (821.25, 1229.88), (1229.88, 1638.5), (1638.5, 2047.12), (2047.12, 2455.75), (2455.75, 2864.38), (2864.38, 3273.0), (2864.38, 3273.0)]\n",
      "tot_debt_to_ebitda [(0.0, 7.62), (7.62, 15.25), (15.25, 22.88), (22.88, 30.5), (30.5, 38.12), (38.12, 45.75), (45.75, 53.38), (53.38, 61.0), (53.38, 61.0)]\n",
      "ebitda_to_tot_int_exp [(-1.0, 2.12), (2.12, 5.25), (5.25, 8.38), (8.38, 11.5), (11.5, 14.62), (14.62, 17.75), (17.75, 20.88), (20.88, 24.0), (20.88, 24.0)]\n",
      "return_on_asset [(-24.0, -18.38), (-18.38, -12.75), (-12.75, -7.12), (-7.12, -1.5), (-1.5, 4.12), (4.12, 9.75), (9.75, 15.38), (15.38, 21.0), (15.38, 21.0)]\n",
      "asset_turnover [(0.0, 0.5), (0.5, 1.0), (1.0, 1.5), (1.5, 2.0), (2.0, 2.5), (2.5, 3.0), (3.0, 3.5), (3.5, 4.0), (3.5, 4.0)]\n"
     ]
    }
   ],
   "source": [
    "for metric in model_metrics:\n",
    "    buckets = get_buckets(min_val.loc[metric].round(0), max_val.loc[metric].round(0))\n",
    "    print(metric, buckets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
